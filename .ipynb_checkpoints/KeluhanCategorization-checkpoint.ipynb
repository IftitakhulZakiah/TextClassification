{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import json\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Keluhan</th>\n",
       "      <th>Respon</th>\n",
       "      <th>Bukan Keluhan/Respon</th>\n",
       "      <th>Topik Umum</th>\n",
       "      <th>Topik Spesifik</th>\n",
       "      <th>Lokasi</th>\n",
       "      <th>Waktu</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6,78845E+17</td>\n",
       "      <td>21 Des 2015, 02.50.25 PM</td>\n",
       "      <td>@EL_Atheos @ridwankamil ya mungkin karena pere...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ya</td>\n",
       "      <td>Bukan Keluhan</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6,78846E+17</td>\n",
       "      <td>21 Des 2015, 02.53.02 PM</td>\n",
       "      <td>@ridwankamil @dbmpkotabdg kang teman saya tert...</td>\n",
       "      <td>Ya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lingkungan Hidup</td>\n",
       "      <td>pohon tumbang</td>\n",
       "      <td>Jalan Sangkuriang depan Polsek Coblong</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6,78847E+17</td>\n",
       "      <td>21 Des 2015, 02.57.55 PM</td>\n",
       "      <td>Di tribun jabar biasanya suka di post agenda k...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ya</td>\n",
       "      <td>Bukan Keluhan</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6,78847E+17</td>\n",
       "      <td>21 Des 2015, 02.58.54 PM</td>\n",
       "      <td>@dbmpkotabdg RT @fajriattack: Lapor pak @ridwa...</td>\n",
       "      <td>Ya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Infrastruktur</td>\n",
       "      <td>lampu penerangan jalan umum</td>\n",
       "      <td>Jalan depan Kampus LPKIA</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6,78849E+17</td>\n",
       "      <td>21 Des 2015, 03.06.49 PM</td>\n",
       "      <td>@diskamtam bapak/ibu mau tanya, kalo pemelihar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ya</td>\n",
       "      <td>Bukan Keluhan</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                 Timestamp  \\\n",
       "0  6,78845E+17  21 Des 2015, 02.50.25 PM   \n",
       "1  6,78846E+17  21 Des 2015, 02.53.02 PM   \n",
       "2  6,78847E+17  21 Des 2015, 02.57.55 PM   \n",
       "3  6,78847E+17  21 Des 2015, 02.58.54 PM   \n",
       "4  6,78849E+17  21 Des 2015, 03.06.49 PM   \n",
       "\n",
       "                                               Tweet Keluhan Respon  \\\n",
       "0  @EL_Atheos @ridwankamil ya mungkin karena pere...     NaN    NaN   \n",
       "1  @ridwankamil @dbmpkotabdg kang teman saya tert...      Ya    NaN   \n",
       "2  Di tribun jabar biasanya suka di post agenda k...     NaN    NaN   \n",
       "3  @dbmpkotabdg RT @fajriattack: Lapor pak @ridwa...      Ya    NaN   \n",
       "4  @diskamtam bapak/ibu mau tanya, kalo pemelihar...     NaN    NaN   \n",
       "\n",
       "  Bukan Keluhan/Respon        Topik Umum               Topik Spesifik  \\\n",
       "0                   Ya     Bukan Keluhan                            -   \n",
       "1                  NaN  Lingkungan Hidup                pohon tumbang   \n",
       "2                   Ya     Bukan Keluhan                            -   \n",
       "3                  NaN     Infrastruktur  lampu penerangan jalan umum   \n",
       "4                   Ya     Bukan Keluhan                            -   \n",
       "\n",
       "                                   Lokasi Waktu  Unnamed: 10  \n",
       "0                                       -      -         NaN  \n",
       "1  Jalan Sangkuriang depan Polsek Coblong      -         NaN  \n",
       "2                                       -      -         NaN  \n",
       "3                Jalan depan Kampus LPKIA      -         NaN  \n",
       "4                                       -      -         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pd.read_csv('data/ica_data.csv', encoding='ISO-8859-1', error_bad_lines=False, delimiter=';')\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = doc.loc[:, 'Tweet':'Bukan Keluhan/Respon']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.fillna('0')\n",
    "# data['Keluhan'] = data['Keluhan'].map({'Ya':1})\n",
    "# data['Respon'] = data['Respon'].map({'Ya':1})\n",
    "# data['Bukan Keluhan/Respon'] = data['Bukan Keluhan/Respon'].map({'Ya':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_text = data.loc[:, 'Tweet']\n",
    "data_tweet = data.loc[:, 'Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_keluhan = data.loc[:, 'Keluhan']\n",
    "# data_keluhan[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index with \"Ya\" value in 3 column\n",
    "temp = data['Keluhan'].values.tolist()\n",
    "idx_keluhan = [i for i, x in enumerate(temp) if x == 'Ya']\n",
    "\n",
    "temp = data['Respon'].values.tolist()\n",
    "idx_respon = [i for i, x in enumerate(temp) if x == 'Ya']\n",
    "\n",
    "temp = data['Bukan Keluhan/Respon'].values.tolist()\n",
    "idx_notboth = [i for i, x in enumerate(temp) if x == 'Ya']\n",
    "\n",
    "# create 1 column for label\n",
    "data_label = []\n",
    "for i in range (0,len(data)):\n",
    "    if i in idx_keluhan:\n",
    "        data_label.append(0)\n",
    "    elif i in idx_respon:\n",
    "        data_label.append(1)\n",
    "    elif i in idx_notboth:\n",
    "        data_label.append(2)\n",
    "data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeURL(sent):\n",
    "    # remove username\n",
    "    sent = re.sub('RT @[^\\s]+','',sent)\n",
    "    sent = re.sub('@[^\\s]+','',sent)\n",
    "    sent = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', sent, flags=re.MULTILINE)\n",
    "    sent = re.sub('http[s]?', '', sent, flags=re.MULTILINE)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(sent):\n",
    "    # text normalization\n",
    "    header = {\n",
    "        'Content-Type' : 'application/json',\n",
    "        'x-api-key' : 'PGSpcyOiDPqdlNmQ1kd66p59qhTDuLUOCqdJk4sF'\n",
    "    }\n",
    "    req = requests.post(\"https://api.prosa.ai/v1/normals\", headers=header, json = { 'text' : sent})\n",
    "    res = req.json()\n",
    "    return res['text']\n",
    "#     print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(sent):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    return stemmer.stem(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(sent):\n",
    "    words = word_tokenize(sent)\n",
    "#     print (words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'ya mungkin karena perempuan bj merah yang paling kelihatan karena berada di depan, laki-laki juga sering jadi bahan joke RK',\n",
       " 'kang teman saya tertimpa pohn di jalan sangkuriang depan polsek coblong tolong ditertibkan pohon yang sudah lapuknuhun']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = '|ya mungkin karena perempuan bj merah yang paling kelihatan karena berada di depan, laki-laki juga sering jadi bahan joke RK|kang teman saya tertimpa pohn di jalan sangkuriang depan polsek coblong tolong ditertibkan pohon yang sudah lapuknuhun'\n",
    "temp.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ya mungkin karena perempuan bj merah yang paling lihat karena ada di depan laki juga sering jadi bahan joke rk kang teman saya timpa pohn dijln sangkuriang depan polsek coblong tolong tertib pohon yang sudah lapuknuhun di tribun jabar biasa suka di pos agenda kang emil tapi tidak tiap hari sih kalau saya bandung bisa temu kang di mana lapor pak lampu terang jalan depan kampus lpkia ngaplek bapak ibu mau tanya kalau pelihara taman yang banyak dibagun sekarang bagaimana nanti pa tempat kerja saya tanggal 25 tetap masuk bagaimana itu atur pa kalau misal enggak masuk potong gaji 00106700466 punten sudah minggu air pdam tidak alir mohon bantu segera anak sma yang tahu curi hem di bip hari ini pak nyata sudah ada warga yang konfirm ke pdam kata air tidak akan alir lama 1 bulan karena ada baik kang jalan di muararajeun baru baru bulan dibenerin sudah rusak lagi yang kerja seperti enggak serius']\n",
      "['didinyamah kieu bosss ku maha pak daerah sapharuhai yeuh kang parkir liar seeur pis atuhda- - pak punten tolong marahin motor yang enggak pakai spakbor belakang sudah mah td hujan wajah rupawan saya kacepretan hatur nuhun dbmp lampu jalan merdeka atos sae kalau mau batas kendara yang feasible dan bisa laku segera dalam wewenang mereka berantas parkir badan jalan pak punten tolong marahin motor yang enggak pakai spakbor belakang sudah mah td hujan wajah rupawan saya kacepretan pak tadi saya habis dari kebun binatang itu bersih masih kurang dan orang utannya juga jomblo pak mohon solusi pak lapor pak mobil ni 2x buang sampah ke pinggir jalan panjang jalan sersan bajuri no 24 bonbin bandung agak kurang awat kasihan sama hewan hewan pak coba bonbin bandung di bikin kayak singapore zoo pak punya saran angkot 08 dan antapani yang coklat lebur saja tetapi arah trayek bagi 2 bagai cimbeuleuit dahulu lapor pak mobil ni 2x buang sampah ke pinggir jalan panjang jalan sersan bajuri no 24']\n",
      "['pak saya lagi mau pulang naik diangkot cheum-ledeng ad ibu sama bapak omong bpak tetapi tenang kok pak omong yang baik2 seperti yang buat jalan macet adlah empat harus ada jamban lyang tiap empat kalau macet begini di lihat di depan karena apa macet angkot bus tem pasti ada sumber titik macet saurwargi tolong ad orang wanita jalan eikman tiap pagi jam 9 suka loncat tengah jalan ambil kunci motor dengan tebus 10 ribu dukung rencana badan hukum angkot jangan sampai kasus metromini jadi nanti di bgr saurwargi tolong ad orang wanita jalan eikman tiap pagi jam 9 suka loncat tengah jalan ambil kunci motor dengan tebus 10 ribu he he perempuan itu belum sudah tanya sama rk dah nikah pa masih single punten saya baru denger berita apa sudah tertib modus ambil kunci motor admin kalau lihat dari foto di bawah ini benar jalan cemara milik trotoar enggak ya tx admin kalau lihat dari foto di bawah ini benar jalan cemara milik trotoar enggak ya tx']\n",
      "['mohon aman pa ogah per4an pasar suci cihaurgeulis buat jalan suci macet total kacau terima kasih perhatiana mohon pasang tiang untuk lampu merah di per4an pasar suci cihaurgeulis sering jadi macet total tuju ini panjang jalan riau banyak yang parkir malah ada yang di trotoar juga ass pak kiaracondong masih banyak lampu jalan yang mati bebek sari 1mohon di baik pak wali upam angkot di bandung ku maha nasibna di jakarta metromini tos jadi korban lapor pak mobil ni 2x buang sampah ke pinggir jalan panjang jalan sersan bajuri no 24 21 12 urc cibeunying eru salur jalan veteran-jalan sunda lapor pak mobil ni 2x buang sampah ke pinggir jalan panjang jalan sersan bajuri no 24 pak iyeu jalmi anu ngabalaan jalan di kota bandung ngabagikeun pamplet tapi di awurz di jalan wartabdg lebih tegas evaluasi sistem gembok parkir']\n",
      "['wartabdg lebih tegas evaluasi sistem gembok parkir wartabdg lebih tegas evaluasi sistem gembok parkir wartabdg lebih tegas evaluasi sistem gembok parkir wartabdg lebih tegas evaluasi sistem gembok parkir wartabdg lebih tegas evaluasi sistem gembok parkir wartabdg lebih tegas evaluasi sistem gembok parkir anak kecil saja jalan2 pke helm masa yang naik motor tidak eta maksad na mah panginteun pakk wartabdg lebih tegas evaluasi sistem gembok parkir libur kang ningali nu meuntas di bip padahal jambat tidak jegir mani gede jeung mani hese hoyong mapah di trotoar di bec teh wartabdg lebih tegas evaluasi sistem gembok parkir']\n",
      "['21 12 urc bojonagara lanjut eru salur jl sukawarna br 21 12 urc bojonagara lanjut baik jalan dr eyckman 21 12 urc bojonagara pasang ubin difabel jl cicendo 21 12 urc tegallega pasang plat beton salur jalan moch toha 21 12 urc ujungberung eru salur jalan golf selatan i 21 12 urc gedebage eru salur jalan sukarno hatta 21 12 urc cibeunying eru salur jalan veteran-jalan sunda 21 12 urc cibeunying lanjut prbaikan kirmir sal jalan gudang utara 21 12 urc bojonagara angkut sendimen jalan sukawarna']\n",
      "['cc rt sangga gedung ini khawatir deh pak roboh lampu terang jalan di panjang jalan bima kel arjuna kec cicendo mati hawatir rawan hatur nuhun wartabdg lebih tegas evaluasi sistem gembok parkir kirmir kali cicadas rw13 kel bbksurabaya longsor mohon bantu cc hatur nuhun urc gedebage atas eru salur merkuri keluarga manjahlega tiap hari lewat bolak balik pa uang habis buat bayar jalan saja ini mah enggak ada cara lain ayo pesan sendal bulu semua size ide 30k hangat nyaman di kaki tikung dari jalan wastu kencana belok ke arah tidak jadi paku bpk dompet saya copet di angkot cheum-dengan pakai seperti a copet a bkrjasama sama seperti angkot a pak tidak saya jadi wanita tetapi identitas pak 21 12 urc pju baik lampu pju jalan ir h djuanda']\n",
      "['21 12 urc pju baik lampu pju jalan rumah sakit jalan jeng sudirman dekat suryani ad kafe mobil parkir dijln dan naik trotoar padahal ad rambu lang parkir cc hati tweeps tikung dari jalan wastu kencana belok ke arah gd paku cc hati tweeps tikung dari jalan wastu kencana belok ke arah gd paku htt dari nmr langgan 00a06600370 margahayu raya j-ii-37 mohon info sudah beberapa hari air tidak keluar lapor pak kemarin malem 20desember teman saya kena bacok oleh 7motor di jalan lodaya lapang soft ball 21 12 urc bojonagara tindaklanjut lap gundu pasir jalan dari otten seperti ini kondisi jalan tuju tpa mohon maaf atas nyaman seperti ini kondisi jalan tuju tpa mohon maaf atas nyaman di informasi kepada wargi bandung atas lambat angkut sampah ditps karena jalan ke arah tpa mcet cc ht']\n"
     ]
    }
   ],
   "source": [
    "n_tweet_per_call = 10 # jumlah tweet untuk setiap call normalisasi\n",
    "n_call = (len(data)/1000) + 1\n",
    "\n",
    "          \n",
    "for i in range (0, n_call):\n",
    "    k = i*n_tweet_per_call\n",
    "    str_temp = ''\n",
    "          \n",
    "    for j in range (i*n_tweet_per_call, (i+1)*n_tweet_per_call):\n",
    "        str_temp = str_temp + \" | \" + data_tweet[j]\n",
    "    \n",
    "    str_temp = removeURL(str_temp)\n",
    "    text = normalization(str_temp)\n",
    "    text = text.encode('ascii', 'ignore')\n",
    "    text = stemmer(text)\n",
    "    temp = text.split('|')\n",
    "    print temp\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = text.split('|')\n",
    "temp\n",
    "\n",
    "(len(data)/1000) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_temp = []\n",
    "# for tweet in data_tweet:\n",
    "#     tweet = removeURL(tweet)\n",
    "#     data_temp.append(tweet)\n",
    "# data_tweet = data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_temp = []\n",
    "# for tweet in data_tweet:\n",
    "#     tweet = stemmer(tweet)\n",
    "#     data_temp.append(tweet)\n",
    "# data_tweet = data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_temp = []\n",
    "# for tweet in data_tweet:\n",
    "#     tweet = tokenizer(tweet)\n",
    "#     data_temp.append(tweet)\n",
    "# data_tweet = data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(data_tweet, min_count=1)\n",
    "model.train(data_tweet, total_examples=1, epochs=1)\n",
    "x = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-21ebd9c73be4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_text' is not defined"
     ]
    }
   ],
   "source": [
    "text_train, text_test, y_train, y_test = train_test_split(data_text, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
